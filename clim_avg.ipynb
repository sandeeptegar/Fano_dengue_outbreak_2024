{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling the Fano 2024, Italy dengue outbreaks: The effects of control strategies and environmental extremes\n",
    "**Author:** Sandeep Tegar<sup>1, 2</sup> and Dominic P. Brass<sup>1</sup> \n",
    "\n",
    "**Contact:** santeg@ceh.ac.uk  \n",
    "**Date:** 2025-03-17   \n",
    "**Affiliation:**\n",
    "1. UK Centre for Ecology & Hydrology, Benson Lane, Wallingford, Oxfordshire, UK\n",
    "2. School of Mathematics and Statistics, College of Science and Engineering, University of Glasgow, Glasgow, UK   \n",
    "\n",
    "\n",
    "## Overview  \n",
    "This notebook contains the code used in our study. It estimates the average climate from 2019-2023  \n",
    "\n",
    "## Requirements  \n",
    "- python 3.9.21+ \n",
    "- Required libraries: `pandas`\n",
    "- ERA5 climate data file \"fano_climate.csv\", coulmns: time, logitude, latitude, t2m, tp, evaow, where 't2m', 'tp', and 'evaow' stand for  \"2m_temperature\", \"total_precipitation\", and \"evaporation_from_open_water_surfaces_excluding_oceans\", respectively. Source: https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land?tab=overview\n",
    "\n",
    "## Usage  \n",
    "Save all the required files in the working directory and simply run the cells in order to reproduce the results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the required package\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "data = pd.read_csv(\"fano_climate.csv\")  # Replace 'your_file.csv' with the actual filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'time' column to datetime format\n",
    "data['time'] = pd.to_datetime(data['time'])\n",
    "\n",
    "# Extract year and day-month for grouping\n",
    "data['year'] = data['time'].dt.year\n",
    "data['day_month'] = data['time'].dt.strftime('%d-%b')\n",
    "\n",
    "# Define the range of dates of interest\n",
    "date_range = [\"13-Sep\", \"14-Sep\", \"15-Sep\", \"16-Sep\", \"17-Sep\", \"18-Sep\", \"19-Sep\", \"20-Sep\", \"21-Sep\", \"22-Sep\", \"23-Sep\", \"24-Sep\"]\n",
    "\n",
    "# Filter data for the specified day-months and year range (2019 to 2023)\n",
    "data = data[(data['year'] >= 2019) & (data['year'] <= 2023)]\n",
    "\n",
    "# Calculate the average over years for the specified day-months\n",
    "result = []\n",
    "for day_month in date_range:\n",
    "    filtered_data = data[data['day_month'] == day_month]\n",
    "    mean_t2m = filtered_data['t2m'].mean()\n",
    "    mean_tp = filtered_data['tp'].mean()\n",
    "    result.append({\n",
    "        'date': day_month,\n",
    "        'mean_t2m': mean_t2m,\n",
    "        'mean_tp': mean_tp\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the result\n",
    "average_data = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>mean_t2m</th>\n",
       "      <th>mean_tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13-Sep</td>\n",
       "      <td>23.278149</td>\n",
       "      <td>8.326673e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14-Sep</td>\n",
       "      <td>23.730373</td>\n",
       "      <td>4.401026e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15-Sep</td>\n",
       "      <td>23.053523</td>\n",
       "      <td>5.998091e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16-Sep</td>\n",
       "      <td>23.102431</td>\n",
       "      <td>3.991490e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17-Sep</td>\n",
       "      <td>22.468396</td>\n",
       "      <td>1.212577e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18-Sep</td>\n",
       "      <td>22.234818</td>\n",
       "      <td>2.820895e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19-Sep</td>\n",
       "      <td>21.504278</td>\n",
       "      <td>3.366778e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20-Sep</td>\n",
       "      <td>20.478219</td>\n",
       "      <td>4.471364e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21-Sep</td>\n",
       "      <td>19.323711</td>\n",
       "      <td>1.209951e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22-Sep</td>\n",
       "      <td>19.901227</td>\n",
       "      <td>5.207284e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>23-Sep</td>\n",
       "      <td>19.561628</td>\n",
       "      <td>4.970166e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>24-Sep</td>\n",
       "      <td>19.511972</td>\n",
       "      <td>5.103796e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      date   mean_t2m       mean_tp\n",
       "0   13-Sep  23.278149  8.326673e-15\n",
       "1   14-Sep  23.730373  4.401026e-03\n",
       "2   15-Sep  23.053523  5.998091e-01\n",
       "3   16-Sep  23.102431  3.991490e+00\n",
       "4   17-Sep  22.468396  1.212577e+00\n",
       "5   18-Sep  22.234818  2.820895e+00\n",
       "6   19-Sep  21.504278  3.366778e+00\n",
       "7   20-Sep  20.478219  4.471364e+00\n",
       "8   21-Sep  19.323711  1.209951e+00\n",
       "9   22-Sep  19.901227  5.207284e+00\n",
       "10  23-Sep  19.561628  4.970166e+00\n",
       "11  24-Sep  19.511972  5.103796e+00"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the average data\n",
    "average_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processing complete. Averages saved to 'average_trend_2019_2023.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Uncomment to write the resulting DataFrame to a new CSV file\n",
    "#average_data.to_csv(\"average_trend_2019_2023.csv\", index=False)\n",
    "\n",
    "#print(\"Data processing complete. Averages saved to 'average_trend_2019_2023.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
